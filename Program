library("dplyr")
library("readr")
library("stringr")
library("ggplot2")
library("devtools")

# Loading files
cv.1<-read.csv2("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/829976e5a515bb84735e5ea96ee5ba93909d96c3/CV.finacorrectl.csv")
dagpenge.1<-read.csv2("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/b7adeedea4268a0b590d83f47c82267101383832/dagpenge.final.csv")
dagpenge.1 <- dagpenge.1[-c(108), ] # deletes the 108. row that is a copy of row 107 (the date appears twice)
job.1<-read.csv2("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/b7adeedea4268a0b590d83f47c82267101383832/job.final.csv")
jobansogning.1<-read.csv2("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/b7adeedea4268a0b590d83f47c82267101383832/Jobansogning.final.csv")
jobindex.1<-read.csv2("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/b7adeedea4268a0b590d83f47c82267101383832/Jobindex.final.csv")
jobnet.1<-read.csv2("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/b7adeedea4268a0b590d83f47c82267101383832/Jobnet.final.csv")
jobportalen.1<-read.csv2("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/b7adeedea4268a0b590d83f47c82267101383832/jobportalen.final.csv")
jobs.1<-read.csv2("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/b7adeedea4268a0b590d83f47c82267101383832/jobs.final.csv")
jobsogning.1<-read.csv2("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/b7adeedea4268a0b590d83f47c82267101383832/jobsogning.final.csv")
jobzonen.1<-read.csv2("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/b7adeedea4268a0b590d83f47c82267101383832/jobzonen.final.csv")
kontanthjaelp.1<-read.csv2("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/b7adeedea4268a0b590d83f47c82267101383832/kontanthjaelp.final.csv")
ledigejob.1<-read.csv2("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/b7adeedea4268a0b590d83f47c82267101383832/ledige%2520job.final.csv")
ledigejobs.1<-read.csv2("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/b7adeedea4268a0b590d83f47c82267101383832/ledige%2520jobs.final.csv")
nytjob.1<-read.csv2("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/b7adeedea4268a0b590d83f47c82267101383832/nyt%2520job.final.csv")
ofir.1<-read.csv2("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/b7adeedea4268a0b590d83f47c82267101383832/ofir.final.csv")

## Loads the actual unemployment rate from Statistics Denmark
library("dkstat")
dst_search(string = "AUS08", field = "text")

dst_meta("AUS08", lang="en") 

AUS08 = dst_get_data(table = "AUS08", OMRÅDE = "All Denmark", 
                     SAESONFAK = "Enumerated actual figures  in percent of the labour force", 
                     Tid = "*",
                     lang='en')
AUS08

# we don't need the column 'område' 
AUS08 <- AUS08[,c(-1)]
# or the column 'saesonfak'
AUS08 <- AUS08[,c(-1)]

# Add row to AUS08 so it is possible to merge with the keywords
AUS08 <- cbind(X=1:nrow(AUS08), AUS08)

# Export the AUS08
#write.csv(file="C:/Users/ml/Desktop/Mette privat/Polit/Polit 9. semester/Social Data Science/Eksamensprojekt/Data/CSV for google trend/AUS08.csv", x=AUS08)

## The unemployment rate is converted to index numbers in excel, 
# where the highest unemployment rate is 6.9
UnemIndex.1 = read_csv("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/b7adeedea4268a0b590d83f47c82267101383832/UnemploymentIndex.csv")

UnemIndex.1 <- cbind(X=1:nrow(UnemIndex.1), UnemIndex.1)
throwout <- c("Var.2", "TID")
UnemIndex.1 <- UnemIndex.1[, ! names(UnemIndex.1) %in% throwout, drop = F]

#################################
library("plyr")
# merges data together by Month (CV has another date format than the rest, so it is merged by X)
merged.data1 <- merge(cv.1, dagpenge.1, by="X")
merged.data1 <- merged.data1[,c(-2)]
merged.data1 = rename(merged.data1, c("Month.y"="Month"))

merged.data2 <- merge(jobsogning.1, jobansogning.1, by="Month")
merged.data3 <- merge(kontanthjaelp.1, ledigejobs.1, by="Month")
merged.data4 <- merge(ledigejob.1, jobnet.1, by="Month")
merged.data5 <- merge(jobindex.1, nytjob.1, by="Month")
merged.data6 <- merge(jobportalen.1, ofir.1, by="Month")
merged.data7 <- merge(job.1, jobs.1, by="Month")
merged.data8 <- merge(merged.data1, merged.data2, by="Month")
merged.data9 <- merge(merged.data3, merged.data8, by="Month")
merged.data10 <- merge(merged.data4, merged.data5, by="Month")
merged.data11 <- merge(merged.data6, merged.data7, by="Month")
merged.data12 <- merge(merged.data11, merged.data10, by="Month")
merged.data13 <- merge(merged.data12, merged.data9, by="Month")

# The X-columns appears too many times, so we delete the all except for one
cols.dont.want <- c("X.x.x.x", "X.y.x.x", "X.x.y.x", "X.y.y.x", "X.x.x.y", "X.y.x.y", "X.x.y.y", "X.y.y.y", "X.y", "X.x.x", "X.y.x", "X.x.y", "X.y.y") # if you want to remove multiple columns
merged.data13 <- merged.data13[, ! names(merged.data13) %in% cols.dont.want, drop = F]

# Reorder the columns
merged.data13 <- merged.data13[,c(12,1,2,3,4,5,6,7,8,9,10,11,13,14,15,16)] 
names(merged.data13)

merged.data14 <- left_join(merged.data13, UnemIndex.1, by="X")

merged.data14$dates <- as.Date(merged.data14$Month, "%m/%d/%y") 
merged.data15 <- merged.data14[,c(1,19,3,4,5,6,7,8,9,10,11,12,13,14,15,16,18)] # move the date to the first column and deletes the month-column
merged.data15=rename(merged.data15, c("X.3"="UnemRate"))

#exports the data frame
#write.csv(file="C:/Users/ml/Desktop/Mette privat/Polit/Polit 9. semester/Social Data Science/Eksamensprojekt/Data/CSV for google trend/data.final3.csv", x=merged.data15)
########################################################################################################################################################

# Start from here
# load the data
# merged.data15 = read.csv("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/4df89ca79b8b4ad0c64f5655350e2d408e6ebf1e/data.final3.csv")
## merged.data17 = read.csv("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/31d0477878cf8909e58e6a5d8637a76297909185/CV.final.csv")
# if you just load the final data (data.final2), you have to delete the first column, X.1, which is weird!
# ONLY IF LOADING: merged.data16=merged.data15[,-c(1)]

merged.data16=merged.data15
#####################

summary(merged.data16)


library(tidyr)
library(dplyr)
## Plots all the variables in one graph
df = merged.data16
df = select(df, -c(X)) # maybe also X.1, 
df = gather(df, indicator, value, -dates)

p = ggplot(df, aes(x = as.Date(dates), y = value, colour = indicator))
p + geom_line()



## The variable Jobportalen has a lot of zeroes, so we delete the variable.
Delete.Jobportalen= c("Jobportalen.Interst.over.time.")
final2= merged.data16[, !names(merged.data16) %in% Delete.Jobportalen, drop = F]
# plot it again
df2 = final2
df2 = select(df2, -c(X)) # maybe also X.1, 
df2 = gather(df2, indicator, value, -dates)

p = ggplot(df2, aes(x = as.Date(dates), y = value, colour = indicator))
p + geom_line()


## Ofir and jobsogning is decreasing over timer, so we delete as well.
## The variable Jobs has one observations that is extremely high, therefore lowering the relative value of the other observations.
Delete.ofjobs= c("Ofir.Interst.over.time.", "Jobsogning.Interst.over.time.", "Jobs.Interst.over.time.")
final3= final2[, !names(final2) %in% Delete.ofjobs, drop = F]
# plot it again
# plot it again
df3 = final3
df3 = select(df3, -c(X)) # maybe also X.1, 
df3 = gather(df3, indicator, value, -dates)

df3 <- unique(df3)

p = ggplot(df3, aes(x = as.Date(dates), y = value, colour = indicator))
p + geom_line()

# plotting the words in small graphs in one image.

df5 = final3
Delete.unemrate= c("UnemRate")
df5= df5[, !names(df5) %in% Delete.unemrate, drop = F]
# plot it again
df5 = select(df5, -c(X)) # maybe also X.1, 
df5 = gather(df5, indicator, value, -dates)
df6<- merge(df5, final3, by="dates")
Delete.all= c("Jobportalen.Interst.over.time.", "Job.Interst.over.time.", "Jobs.Interst.over.time.", "Ledige.job.Interst.over.time.", "Jobnet.Interst.over.time.", "jobindex.Interst.over.time.", "Nyt.job.Interst.over.time.", "Kontanthjaelp.Interst.over.time.", "Ledige.jobs.Interst.over.time.", "CV.Interst.over.time.", "dagpenge.Interst.over.time.", "Jobansogning.Interst.over.time.")
df6b= df6[, !names(df6) %in% Delete.all, drop = F]

library("ggplot2")
p = ggplot(df6b, aes(x = as.Date(dates), y = value))
p + geom_smooth() + facet_wrap(~ indicator)+ 
  geom_smooth(aes(y=UnemRate), colour="red")
#here we purely see the overal trend, not the short term trends.

# plotting the words with the indexed unemployment. This might be possible in a simpler way, however I feel that for us it is more practical to focus on getting things to work. Not on the most efficient code.

ggplot(final3, aes(x = as.Date(dates))) + 
  geom_line(aes(y = Job.Interst.over.time.), colour="blue") + 
  geom_line(aes(y = UnemRate), colour = "grey") + 
  ylab(label="Index") + 
  xlab("Date")

ggplot(final3, aes(x = as.Date(dates))) + 
  geom_line(aes(y = Ledige.job.Interst.over.time.), colour="blue") + 
  geom_line(aes(y = UnemRate), colour = "grey") + 
  ylab(label="Index") + 
  xlab("Date")

ggplot(final3, aes(x = as.Date(dates))) + 
  geom_line(aes(y = Jobnet.Interst.over.time.), colour="blue") + 
  geom_line(aes(y = UnemRate), colour = "grey") + 
  ylab(label="Index") + 
  xlab("Date")

ggplot(final3, aes(x = as.Date(dates))) + 
  geom_line(aes(y = jobindex.Interst.over.time.), colour="blue") + 
  geom_line(aes(y = UnemRate), colour = "grey") + 
  ylab(label="Index") + 
  xlab("Date")

ggplot(final3, aes(x = as.Date(dates))) + 
  geom_line(aes(y = Nyt.job.Interst.over.time.), colour="blue") + 
  geom_line(aes(y = UnemRate), colour = "grey") + 
  ylab(label="Index") + 
  xlab("Date")
#seems to have an inverse relationship. 

ggplot(final3, aes(x = as.Date(dates))) + 
  geom_line(aes(y = Kontanthjaelp.Interst.over.time.), colour="blue") + 
  geom_line(aes(y = UnemRate), colour = "grey") + 
  ylab(label="Index") + 
  xlab("Date")

ggplot(final3, aes(x = as.Date(dates))) + 
  geom_line(aes(y = Ledige.jobs.Interst.over.time.), colour="blue") + 
  geom_line(aes(y = UnemRate), colour = "grey") + 
  ylab(label="Index") + 
  xlab("Date")
#inverse relatonship

ggplot(final3, aes(x = as.Date(dates))) + 
  geom_line(aes(y = CV.Interst.over.time.), colour="blue") + 
  geom_line(aes(y = UnemRate), colour = "grey") + 
  ylab(label="Index") + 
  xlab("Date")

ggplot(final3, aes(x = as.Date(dates))) + 
  geom_line(aes(y = dagpenge.Interst.over.time.), colour="blue") + 
  geom_line(aes(y = UnemRate), colour = "grey") + 
  ylab(label="Index") + 
  xlab("Date")

ggplot(final3, aes(x = as.Date(dates))) + 
  geom_line(aes(y = Jobansogning.Interst.over.time.), colour="blue") + 
  geom_line(aes(y = UnemRate), colour = "grey") + 
  ylab(label="Index") + 
  xlab("Date")




######################################

unem=read_csv("https://gist.githubusercontent.com/Bob30/75e994a523f622943a3d/raw/e5963dee7d567dbd2c44c952658e9a6586d26ed9/AUS08.csv")
unem<-unem[,c (-1,-2)]
colnames(unem)[1] <- "dates"

# Trying to make an index
df.wide = df3 %>% spread(indicator, value)
df.wide = df.wide[complete.cases(df.wide), ]
df.wide$dates<- as.Date(df.wide$dates, "%Y-%m-%d")
head(df.wide)

pca = princomp(select(df.wide, -c(dates,UnemRate)))
summary(pca)

#Creating an index
unemployment.index = predict(pca)[, 1]
unemployment.index = data.frame(unemployment.index = unemployment.index, dates = df.wide$dates)




# Compare to unemployment rate
library("lubridate")
# Unemploymentrate = df.wide %>% select(dates, UnemRate)
unemployment.data = full_join(unemployment.index, unem)

head(unemployment.data)


## Plot
unemployment.data = unemployment.data %>% 
  mutate(
    unemployment.index = scale(unemployment.index * (-1)),
    value = scale(value)
  )
unemployment.data = unemployment.data %>% gather(index, actual.unemployment, -dates)
head(unemployment.data)



## Plot
p = ggplot(unemployment.data, aes(x = dates, y = actual.unemployment, group = index, colour = index))
p + geom_smooth()  + theme_minimal()
#The part of the graph that is beneath the actual unem: maybe due to CV. It has a extreme drop between 2010-2012


############
# Regressions
#first, I regress only the variables that we kept in final3.
reg2 = lm(UnemRate ~ Job.Interst.over.time. + Ledige.jobs.Interst.over.time. + Ledige.job.Interst.over.time. + Jobnet.Interst.over.time. + jobindex.Interst.over.time. + Nyt.job.Interst.over.time. + Kontanthjaelp.Interst.over.time. + Ledige.jobs.Interst.over.time. +CV.Interst.over.time. + dagpenge.Interst.over.time. + Jobansogning.Interst.over.time., data=final3) 
summary(reg2)

# second, I regress the significant variables (made a bit sloppy, so we should doublecheck)
reg3 = lm(UnemRate ~ Job.Interst.over.time. + Ledige.job.Interst.over.time. + jobindex.Interst.over.time. + CV.Interst.over.time. + Jobansogning.Interst.over.time., data=final3) 
summary(reg3)

# Trying to make an index with only significant variables.
Delete.unsig= c("Ledige.job.Interst.over.time.", "Jobnet.Interst.over.time.", "Kontanthjaelp.Interst.over.time.", "dagpenge.Interst.over.time.")
final3.2= final3[, !names(final3) %in% Delete.unsig, drop = F]
df3.2 = final3.2
df3.2 = select(df3.2, -c(X)) # maybe also X.1, 
df3.2 = gather(df3.2, indicator, value, -dates)

df3.2 <- unique(df3.2)

df.wide2 = df3.2 %>% spread(indicator, value)
df.wide2 = df.wide2[complete.cases(df.wide2), ]
df.wide2$dates<- as.Date(df.wide2$dates, "%Y-%m-%d")
head(df.wide2)

#PCA (fjerner dates og den reelle unemployment rate)
pca.2 = princomp(select(df.wide2, -c(dates,UnemRate)))
summary(pca.2)

#Creating an index
unemployment.index.2 = predict(pca.2)[, 1]
unemployment.index.2 = data.frame(unemployment.index.2 = unemployment.index.2, dates = df.wide2$dates)


# Compare to unemployment rate
#install.packages("lubridate")
library("lubridate")
# Unemploymentrate = df.wide %>% select(dates, UnemRate)
unemployment.data.2 = full_join(unemployment.index.2, unem)

head(unemployment.data.2)


## Plot
unemployment.data.2 = unemployment.data.2 %>% 
  mutate(
    unemployment.index.2 = scale(unemployment.index.2 * (-1)),
    value = scale(value)
  )
unemployment.data.2 = unemployment.data.2 %>% gather(index, actual.unemployment, -dates)
head(unemployment.data.2)


## Plot
p = ggplot(unemployment.data.2, aes(x = dates, y = actual.unemployment, group = index, colour = index))
p + geom_smooth()  + theme_minimal()
#Our original graph of the prediction with all variables we selected seems to be more accurate than this one.


## Index with job, nyt job, ledige jobs inverse because our we can't predict as of now> the unemployment trend predicts the google search now.
## Exclude dagpenge, exclude kontant
## both needs to be done.
final3.2$Y      <- c("100")
final3.2$Y=as.integer(final3.2$Y)  
final3.2$Inverse.Job <- (final3.2$Y-final3.2$Job.Interst.over.time.)

df3.2 = final3.2
df3.2 = select(df3.2, -c(X)) # maybe also X.1, 
df3.2 = gather(df3.2, indicator, value, -dates)

df3.2 <- unique(df3.2)

df.wide2 = df3.2 %>% spread(indicator, value)
df.wide2 = df.wide2[complete.cases(df.wide2), ]
df.wide2$dates<- as.Date(df.wide2$dates, "%Y-%m-%d")
head(df.wide2)

#PCA (fjerner dates og den reelle unemployment rate)
pca.2 = princomp(select(df.wide2, -c(dates,UnemRate)))
summary(pca.2)

#Creating an index
unemployment.index.2 = predict(pca.2)[, 1]
unemployment.index.2 = data.frame(unemployment.index.2 = unemployment.index.2, dates = df.wide2$dates)


# Compare to unemployment rate
#install.packages("lubridate")
library("lubridate")
# Unemploymentrate = df.wide %>% select(dates, UnemRate)
unemployment.data.2 = full_join(unemployment.index.2, unem)

head(unemployment.data.2)


## Plot
unemployment.data.2 = unemployment.data.2 %>% 
  mutate(
    unemployment.index.2 = scale(unemployment.index.2 * (-1)),
    value = scale(value)
  )
unemployment.data.2 = unemployment.data.2 %>% gather(index, actual.unemployment, -dates)
head(unemployment.data.2)


## Plot
p = ggplot(unemployment.data.2, aes(x = dates, y = actual.unemployment, group = index, colour = index))
p + geom_smooth()  + theme_minimal()
